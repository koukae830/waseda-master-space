#### Assignment 2

### **Q1: McCulloch-Pitts Neuron**

In this question, I introduced the McCulloch-Pitts neuron, a simple mathematical model inspired by biological neurons. I drew the structure of a biological neuron and explained the correspondence:

- Dendrites correspond to input terminals.
- The cell body performs the summation of inputs.
- The axon transmits the output signal.
- Synapses represent the weights between neurons.

The McCulloch-Pitts neuron computes a weighted sum and applies a step function. I then showed how to build logic gates using this model:

- **AND gate**: weights = [1, 1], bias = -1.5
- **OR gate**: weights = [1, 1], bias = -0.5

Finally, I discussed why the **XOR gate cannot be implemented** with a single McCulloch-Pitts neuron â€” because XOR is not linearly separable.

------

### ğŸŸ© **Q2: MLP with Skip Connections (XOR Solver)**

In this part, I analyzed a Multi-Layer Perceptron with a hidden neuron and a skip connection from input to output.

- I created a truth table showing that the network outputs correct XOR results.
- For **xâ‚ƒ**, I derived the equation: `xâ‚ƒ = step(xâ‚ + xâ‚‚ - 1.5)`. I drew the decision boundary: a line `xâ‚ + xâ‚‚ = 1.5`.
- For **xâ‚„**, the output is `xâ‚„ = step(xâ‚ - xâ‚‚ + 0.5)`, so the decision line is `xâ‚ - xâ‚‚ = -0.5`.

These nonlinear boundaries together enable solving XOR.

------

### ğŸŸ© **Q3: Activation Functions**

I introduced three popular activation functions:

- **Sigmoid**: outputs between 0 and 1
- **Tanh**: outputs between -1 and 1
- **ReLU**: outputs 0 for negative input, and x for positive input

I sketched all three on coordinate planes to show their behavior.

------

### ğŸŸ© **Q4: Shape of Parameters & Forward Pass**

I described the matrix shapes of weights and biases in a standard feedforward neural network:

- **W1**: shape (d, h) â€” from input to hidden
- **b1**: shape (1, h)
- **W2**: shape (h, c) â€” from hidden to output
- **b2**: shape (1, c)

For input **x (1Ã—d)**, I wrote:

```
f(x) = softmax(ReLU(xW1 + b1)W2 + b2)
```

And for batch input **X (nÃ—d)**:

```
f(X) = softmax(ReLU(XW1 + b1)W2 + b2)
```

------

### ğŸŸ© **Programming Part**

In Python, I implemented 3 neural networks:

1. **ANN1**: 2 input â†’ 2 output (no hidden layer), with softmax
2. **ANN2**: 2 input â†’ 8 hidden (no activation) â†’ 2 output, with softmax
3. **ANN3**: 2 input â†’ 8 hidden (ReLU) â†’ 2 output, with softmax

I used `matplotlib.pyplot.contourf()` to visualize decision boundaries.

- ANN1 has linear boundaries due to no hidden layer.
- ANN2 shows more complex patterns than ANN1, but still limited because it lacks non-linearity.
- ANN3 performs best, showing nonlinear decision boundaries thanks to the ReLU activation in the hidden layer.

I concluded that **multi-layer networks with non-linear activation** are superior because they can approximate complex functions and classify data that are not linearly separable.



#### Assignment 4

### Q1 â€“ Key Idea of Backpropagation

> "The Backpropagation algorithm is a supervised learning technique used to train neural networks by minimizing the error between predicted and actual outputs.
>  It consists of a forward pass to compute the output, and a backward pass to compute the gradients using the chain rule.
>  These gradients are then used to update weights through gradient descent."

### Q2

 <img src="assets/image-20250718170909790.png" alt="image-20250718170909790" style="zoom:67%;" />

 <img src="assets/image-20250718171005944.png" alt="image-20250718171005944" style="zoom:67%;" />

> "To answer Q2-2 efficiently, I wrote a Python script to simulate four steps of backpropagation training on a 1-2-1 MLP, using ReLU activation.
>  This helped automate the calculations of intermediate values such as activations, errors, gradients, and weight updates."

> "Hereâ€™s how the code works:"

------

### ğŸ”¹ 1. **Initialization**

```
pythonå¤åˆ¶ç¼–è¾‘x = 0.7
d = 0.68
mu = 0.2
W1 = np.array([0.3, -0.3])
b1 = np.array([0.0, 0.0])
W2 = np.array([-0.1, 0.1])
b2 = 0.0
```

> "The input `x` is 0.7, and the target output `d` is 0.68.
>  Weights and biases for the hidden layer (`W1`, `b1`) and output layer (`W2`, `b2`) are initialized manually.
>  The learning rate `mu` is set to 0.2."

**ä¸­æ–‡ç¿»è¯‘ï¼š**

> â€œè¾“å…¥ `x` æ˜¯ 0.7ï¼Œç›®æ ‡å€¼ `d` æ˜¯ 0.68ã€‚
>  æˆ‘æ‰‹åŠ¨åˆå§‹åŒ–äº†éšè—å±‚çš„æƒé‡å’Œåç½®ï¼ˆ`W1`, `b1`ï¼‰ï¼Œä»¥åŠè¾“å‡ºå±‚ï¼ˆ`W2`, `b2`ï¼‰ã€‚
>  å­¦ä¹ ç‡è®¾ä¸º 0.2ã€‚â€

------

### ğŸ”¹ 2. **Forward Pass and Backward Pass (Loop over 4 steps)**

```
pythonå¤åˆ¶ç¼–è¾‘for t in range(steps):
    z1 = W1 * x + b1
    Z = relu(z1)
    z2 = np.dot(W2, Z) + b2
    y = z2
```

> "In each training step, I compute the hidden layer activation `Z` using ReLU, and the output `y` is computed as a linear combination of `Z` and weights `W2`."

------

### ğŸ”¹ 3. **Compute Errors and Gradients**

```
pythonå¤åˆ¶ç¼–è¾‘delta2 = y - d
delta1 = relu_derivative(z1) * W2 * delta2

deltaW2 = mu * delta2 * Z
deltaW1 = mu * delta1 * x
```

> "Then I compute the output error `delta2` and backpropagate it to get `delta1`.
>  These are used to compute weight updates `deltaW1`, `deltaW2`, and corresponding bias updates."

**ä¸­æ–‡ç¿»è¯‘ï¼š**

> â€œæˆ‘è®¡ç®—è¾“å‡ºè¯¯å·® `delta2`ï¼Œå†é€šè¿‡é“¾å¼æ³•åˆ™è®¡ç®— `delta1`ã€‚
>  ç„¶åç”¨è¿™äº›è¯¯å·®è®¡ç®—æ¯ä¸€å±‚çš„æƒé‡å’Œåç½®æ›´æ–°é‡ã€‚â€

------

### ğŸ”¹ 4. **Update Weights and Log Results**

```
pythonå¤åˆ¶ç¼–è¾‘W1 -= deltaW1
W2 -= deltaW2
b1 -= mu * delta1
b2 -= mu * delta2
```

> "After computing the gradients, I update the weights and biases.
>  I also log all intermediate results such as weights, activations, deltas, and gradients in a table format."

**ä¸­æ–‡ç¿»è¯‘ï¼š**

> â€œå®Œæˆæ¢¯åº¦è®¡ç®—åï¼Œæˆ‘æ›´æ–°äº†æ¯ä¸€å±‚çš„æƒé‡å’Œåç½®ã€‚
>  æˆ‘è¿˜æŠŠæ‰€æœ‰ä¸­é—´ç»“æœï¼ˆå¦‚æƒé‡ã€æ¿€æ´»å€¼ã€è¯¯å·®ã€æ¢¯åº¦ç­‰ï¼‰è®°å½•åˆ°è¡¨æ ¼ä¸­ã€‚â€

------

### ğŸ”¹ 5. **Result Table Output**

> "The result is a clear, step-by-step table showing all variables for each training step, which matches the requirement of Q2-2.
>  This approach ensures accurate, repeatable calculations and saved time compared to manual derivation."

**ä¸­æ–‡ç¿»è¯‘ï¼š**

> â€œæœ€ç»ˆç»“æœæ˜¯ä¸€ä¸ªæ¸…æ™°çš„è¡¨æ ¼ï¼Œè®°å½•äº†æ¯ä¸€è½®è®­ç»ƒçš„æ‰€æœ‰å˜é‡ï¼Œå®Œå…¨ç¬¦åˆQ2-2é¢˜ç›®çš„è¦æ±‚ã€‚
>  ç›¸æ¯”æ‰‹åŠ¨æ¨å¯¼ï¼Œè¿™ç§æ–¹æ³•æ›´é«˜æ•ˆã€æ›´å‡†ç¡®ï¼Œä¹Ÿæ˜“äºå¤æŸ¥ã€‚â€



ç¼–ç¨‹é¢˜

> "In the second part of the assignment, I implemented a neural network from scratch in Python using NumPy to solve the two-spiral classification task.
>  I generated two classes of spiral data in 2D and used a fully connected network to separate them."

> "The network has:

- 2 inputs
- Two hidden layers (each with 16 units)
- 1 output (sigmoid for binary classification)"

> "I trained the model using the same BP principles I derived earlier."

**ä¸­æ–‡ç¿»è¯‘ï¼š**

> â€œä½œä¸šçš„ç¬¬äºŒéƒ¨åˆ†æ˜¯ç”¨Pythonå’ŒNumPyä»é›¶å®ç°ç¥ç»ç½‘ç»œï¼Œä»¥è§£å†³åŒèºæ—‹åˆ†ç±»é—®é¢˜ã€‚
>  æˆ‘ç”Ÿæˆäº†ä¸¤ç±»äºŒç»´èºæ—‹æ•°æ®ï¼Œå¹¶ä½¿ç”¨ä¸€ä¸ªå‰é¦ˆç¥ç»ç½‘ç»œå¯¹å…¶è¿›è¡Œåˆ†ç±»ã€‚â€

> â€œç½‘ç»œç»“æ„åŒ…æ‹¬ï¼š

- ä¸¤ä¸ªè¾“å…¥
- ä¸¤å±‚éšè—å±‚ï¼ˆæ¯å±‚16ä¸ªç¥ç»å…ƒï¼‰
- ä¸€ä¸ªè¾“å‡ºèŠ‚ç‚¹ï¼ˆsigmoidç”¨äºäºŒåˆ†ç±»ï¼‰â€

> â€œæˆ‘ä½¿ç”¨äº†å’Œæ‰‹æ¨å…¬å¼ä¸€è‡´çš„åå‘ä¼ æ’­æ–¹æ³•è¿›è¡Œè®­ç»ƒã€‚â€

------

### ğŸ”· Slide 6: Code Details and Results

> "In the code:

- `train_nn()` runs forward and backward propagation for 2000 epochs
- `forward_pass()` is used to plot the decision boundary
- Loss was calculated using mean squared error"

> "I plotted:

- A training loss curve (which shows convergence)
- A decision boundary plot (showing the learned separation)"

**ä¸­æ–‡ç¿»è¯‘ï¼š**

> â€œåœ¨ä»£ç ä¸­ï¼š

- `train_nn()` å‡½æ•°æ‰§è¡Œå‰å‘å’Œåå‘ä¼ æ’­å…±2000è½®
- `forward_pass()` ç”¨äºç»˜åˆ¶å†³ç­–è¾¹ç•Œ
- æŸå¤±å‡½æ•°ä½¿ç”¨çš„æ˜¯å‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰â€

> â€œæˆ‘ç»˜åˆ¶äº†ï¼š

- è®­ç»ƒæŸå¤±æ›²çº¿ï¼ˆæ˜¾ç¤ºæ¨¡å‹æ”¶æ•›è¿‡ç¨‹ï¼‰
- å†³ç­–è¾¹ç•Œå›¾ï¼ˆæ˜¾ç¤ºæ¨¡å‹å¯¹èºæ—‹æ•°æ®çš„åˆ†ç¦»æ•ˆæœï¼‰â€

------

### ğŸ”· Slide 7: Reflection

> "It was challenging to implement the BP algorithm fully by hand.
>  I had to carefully calculate each derivative and verify the gradient shapes.
>  Normalizing the data and tuning the learning rate were crucial for successful training."

**ä¸­æ–‡ç¿»è¯‘ï¼š**

> â€œæ‰‹åŠ¨å®ç°å®Œæ•´çš„BPç®—æ³•æ˜¯æœ‰æŒ‘æˆ˜æ€§çš„ã€‚
>  æˆ‘éœ€è¦éå¸¸ä»”ç»†åœ°è®¡ç®—æ¯ä¸€å±‚çš„å¯¼æ•°å¹¶ç¡®ä¿æ¢¯åº¦ç»´åº¦ä¸€è‡´ã€‚
>  å¯¹æ•°æ®è¿›è¡Œå½’ä¸€åŒ–ã€è°ƒæ•´å­¦ä¹ ç‡æ˜¯è®­ç»ƒæˆåŠŸçš„å…³é”®ã€‚â€



#### Assignment 5

###  Q1 â€“ Convolutional Neural Network Architecture

> "The question provided a CNN architecture with two convolutional layers, one pooling layer, and two fully connected layers.
>  I calculated the number of weights and biases for each layer based on kernel sizes, channels, and units."

#### â–ª Weights & Biases:

- Conv1: 4Ã—4Ã—3Ã—8=3844Ã—4Ã—3Ã—8 = 3844Ã—4Ã—3Ã—8=384 weights + 8 biases
- Conv2: 8Ã—8Ã—8Ã—16=81928Ã—8Ã—8Ã—16 = 81928Ã—8Ã—8Ã—16=8192 weights + 16 biases
- FC1: 1024Ã—64=655361024Ã—64 = 655361024Ã—64=65536 weights + 64 biases
- FC2: 64Ã—8=51264Ã—8 = 51264Ã—8=512 weights + 8 biases
   **Total: 74,624 weights, 96 biases**

#### â–ª Output Shapes:

- Input: 84Ã—84Ã—3
- Conv1: 84Ã—84Ã—8
- Conv2: 26Ã—26Ã—16 (due to stride 3 and valid padding)
- Pooling: 8Ã—8Ã—16
- FC1: 64, FC2: 8, Softmax: 8

#### â–ª Receptive Field:

- Final receptive field after pooling = **17Ã—17**

### Q2 â€“ 1D Convolution Output Derivation

> "Given a 1D input signal and specified filters, I manually computed each output using valid padding, stride 1, and no activation."

#### â–ª Conv1 Filters:

- Filter1 [0,1,0] â†’ output: [2, 6, 7, 8, 9]
- Filter2 [0,0,1] â†’ output: [6, 7, 8, 9, 1]
- Filter3 [1,0,0] â†’ output: [1, 2, 6, 7, 8]
- Filter4 [1,0,1] â†’ output: [7, 9, 14, 16, 9]

#### â–ª Conv2:

- 1 filter, kernel size = 3Ã—4, all weights = 1
- Result: [75, 99, 102]



### Q3 â€“ Unrolling Deep RNNs

> "For this question, I described how deep RNNs are unrolled through time.
>  Each time step feeds into multiple RNN layers vertically.
>  Horizontally, the hidden states propagate across time, and final outputs are taken from the last time step of the final layer."



ç¼–ç¨‹

###  1. **Importing Libraries**

```
pythonå¤åˆ¶ç¼–è¾‘import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision
import torchvision.transforms as transforms
```

> "I start by importing PyTorch and torchvision libraries.
>  These provide modules for defining neural networks, activation functions, and data transformations."

**ä¸­æ–‡ç¿»è¯‘ï¼š**

> â€œé¦–å…ˆå¯¼å…¥äº† PyTorch å’Œ torchvision åº“ï¼Œå®ƒä»¬æä¾›äº†å®šä¹‰ç¥ç»ç½‘ç»œã€æ¿€æ´»å‡½æ•°ã€æ•°æ®è½¬æ¢ç­‰å¿…è¦çš„æ¨¡å—ã€‚â€

------

### ğŸ”¹ 2. **Define the CNN Class**

```
pythonå¤åˆ¶ç¼–è¾‘class MyCNN(nn.Module):
    def __init__(self):
        super(MyCNN, self).__init__()
        ...
```

> "I defined a class called `MyCNN`, which inherits from `nn.Module`.
>  Inside the constructor `__init__`, I define all the layers of my convolutional neural network."

**ä¸­æ–‡ç¿»è¯‘ï¼š**

> â€œæˆ‘å®šä¹‰äº†ä¸€ä¸ªç±» `MyCNN`ï¼Œç»§æ‰¿è‡ª PyTorch çš„ `nn.Module`ï¼Œ
>  åœ¨æ„é€ å‡½æ•° `__init__()` ä¸­å®šä¹‰äº†CNNæ¨¡å‹çš„æ‰€æœ‰ç½‘ç»œå±‚ã€‚â€

------

### ğŸ”¹ 3. **Network Layers**

```
pythonå¤åˆ¶ç¼–è¾‘self.conv1 = nn.Conv2d(1, 16, kernel_size=5, padding=2)
self.bn1 = nn.BatchNorm2d(16)
self.pool1 = nn.MaxPool2d(2)

self.conv2 = nn.Conv2d(16, 32, kernel_size=5, padding=2)
self.bn2 = nn.BatchNorm2d(32)
self.pool2 = nn.MaxPool2d(2)

self.fc1 = nn.Linear(32*7*7, 128)
self.dropout = nn.Dropout(0.5)
self.fc2 = nn.Linear(128, 10)
```

> "The CNN has:

- 2 convolutional layers (with batch normalization and max pooling)
- A fully connected layer with dropout
- A final output layer with 10 classes for MNIST"

> "I used kernel size = 5, and padding = 2 to maintain image size."

**ä¸­æ–‡ç¿»è¯‘ï¼š**

> â€œæ¨¡å‹åŒ…æ‹¬ï¼š

- ä¸¤ä¸ªå·ç§¯å±‚ï¼ˆæ¯ä¸ªåæ¥ BatchNorm å’Œ MaxPoolingï¼‰
- ä¸€ä¸ªå…¨è¿æ¥å±‚ + Dropoutï¼ˆé˜²æ­¢è¿‡æ‹Ÿåˆï¼‰
- æœ€åä¸€å±‚ä¸º10ä¸ªç±»åˆ«è¾“å‡ºï¼ˆç”¨äºMNISTï¼‰â€

------

### ğŸ”¹ 4. **Forward Function**

```
pythonå¤åˆ¶ç¼–è¾‘def forward(self, x):
    x = self.pool1(F.relu(self.bn1(self.conv1(x))))
    x = self.pool2(F.relu(self.bn2(self.conv2(x))))
    x = x.view(-1, 32 * 7 * 7)
    x = self.dropout(F.relu(self.fc1(x)))
    x = self.fc2(x)
    return x
```

> "The forward method defines how input data flows through the network:

1. Conv â†’ BN â†’ ReLU â†’ Pool
2. Conv â†’ BN â†’ ReLU â†’ Pool
3. Flatten
4. Fully connected layer + dropout
5. Output layer"

**ä¸­æ–‡ç¿»è¯‘ï¼š**

> â€œ`forward()` å‡½æ•°å®šä¹‰äº†æ•°æ®åœ¨ç½‘ç»œä¸­çš„æµåŠ¨æ–¹å¼ï¼š

1. å·ç§¯ â†’ BN â†’ ReLU â†’ æ± åŒ–
2. å·ç§¯ â†’ BN â†’ ReLU â†’ æ± åŒ–
3. æ‹‰å¹³ä¸ºå‘é‡
4. è¿›å…¥å…¨è¿æ¥å±‚ï¼ˆå¸¦ Dropoutï¼‰
5. è¾“å‡ºå±‚ç»™å‡ºåˆ†ç±»ç»“æœâ€

------

### ğŸ”¹ 5. **Data Preprocessing**

```
pythonå¤åˆ¶ç¼–è¾‘transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])
trainset = torchvision.datasets.MNIST(...)
trainloader = torch.utils.data.DataLoader(...)
```

> "Here I downloaded the MNIST dataset and applied normalization using torchvision.
>  Images are converted to tensors and pixel values are normalized to [-1, 1]."

**ä¸­æ–‡ç¿»è¯‘ï¼š**

> â€œä½¿ç”¨ `torchvision` ä¸‹è½½MNISTæ•°æ®é›†ï¼Œå¹¶è¿›è¡Œæ ‡å‡†åŒ–å¤„ç†ï¼š
>  å›¾åƒè¢«è½¬æ¢ä¸ºå¼ é‡ï¼Œå¹¶å°†åƒç´ å€¼å½’ä¸€åŒ–åˆ° [-1, 1] åŒºé—´ã€‚â€

------

### ğŸ”¹ 6. **Training Setup**

```
pythonå¤åˆ¶ç¼–è¾‘model = MyCNN()
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
```

> "I used:

- `CrossEntropyLoss` as the loss function (suitable for multi-class classification)
- `Adam` optimizer with learning rate = 0.001"

**ä¸­æ–‡ç¿»è¯‘ï¼š**

> â€œä½¿ç”¨äº¤å‰ç†µæŸå¤±å‡½æ•°ï¼ˆé€‚ç”¨äºå¤šåˆ†ç±»ä»»åŠ¡ï¼‰å’ŒAdamä¼˜åŒ–å™¨ï¼Œå­¦ä¹ ç‡è®¾ç½®ä¸º0.001ã€‚â€

------

### ğŸ”¹ 7. **Training Loop**

```
pythonå¤åˆ¶ç¼–è¾‘for epoch in range(num_epochs):
    for i, (images, labels) in enumerate(trainloader):
        outputs = model(images)
        loss = criterion(outputs, labels)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
```

> "The model is trained for several epochs.
>  In each iteration:

- Compute prediction
- Calculate loss
- Backpropagate and update weights"

**ä¸­æ–‡ç¿»è¯‘ï¼š**

> â€œæ¨¡å‹è¿›è¡Œäº†å¤šè½®è¿­ä»£è®­ç»ƒï¼Œæ¯è½®åŒ…æ‹¬ï¼š

- å‰å‘ä¼ æ’­è®¡ç®—è¾“å‡º
- è®¡ç®—æŸå¤±
- åå‘ä¼ æ’­å¹¶æ›´æ–°æƒé‡â€

------

### ğŸ”¹ 8. **Evaluation and Accuracy**

```
pythonå¤åˆ¶ç¼–è¾‘with torch.no_grad():
    correct = 0
    total = 0
    for images, labels in testloader:
        outputs = model(images)
        _, predicted = torch.max(outputs.data, 1)
        correct += (predicted == labels).sum().item()
```

> "After training, I evaluated the model accuracy on the test dataset.
>  Predicted labels are compared with true labels to compute the total accuracy."

**ä¸­æ–‡ç¿»è¯‘ï¼š**

> â€œè®­ç»ƒå®Œæˆåï¼Œæˆ‘åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æ¨¡å‹å‡†ç¡®ç‡ã€‚
>  ä½¿ç”¨ `torch.max()` è·å–æœ€å¤§æ¦‚ç‡å¯¹åº”çš„é¢„æµ‹ç±»åˆ«ï¼Œå¹¶ä¸çœŸå®æ ‡ç­¾è¿›è¡Œæ¯”è¾ƒã€‚â€